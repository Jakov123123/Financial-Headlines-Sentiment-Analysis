{"cells":[{"cell_type":"markdown","source":["# **Financial Headlines Sentiment Analysis**\n","# Author: Jakov Vodanović"],"metadata":{"id":"eJPNyQJqdE4X"},"id":"eJPNyQJqdE4X"},{"cell_type":"markdown","source":["# Loading data and essential libraries."],"metadata":{"id":"NZUzVPM1thbX"},"id":"NZUzVPM1thbX"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hSWlwRb14DRi","executionInfo":{"status":"ok","timestamp":1704545869586,"user_tz":-60,"elapsed":16473,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"6ef7994e-d042-4f48-8ca1-bcfc75e113bd"},"id":"hSWlwRb14DRi","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["If you wish to do this yourself, you will have to change the path."],"metadata":{"id":"inpiFMcJ2hA-"},"id":"inpiFMcJ2hA-"},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Arhitekture neuronskih mreža/Projekt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LMuIxjp-4EU5","executionInfo":{"status":"ok","timestamp":1704545869587,"user_tz":-60,"elapsed":4,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"f695a198-4a86-4a54-b7c4-2359c8d571b9"},"id":"LMuIxjp-4EU5","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Arhitekture neuronskih mreža/Projekt\n"]}]},{"cell_type":"code","execution_count":3,"id":"economic-thomson","metadata":{"id":"economic-thomson","executionInfo":{"status":"ok","timestamp":1704545906087,"user_tz":-60,"elapsed":5573,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import time\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":4,"id":"current-vocabulary","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"current-vocabulary","executionInfo":{"status":"ok","timestamp":1704545907323,"user_tz":-60,"elapsed":396,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"9ed94696-cc4b-4463-ebcb-e79ee4b6daef"},"outputs":[{"output_type":"stream","name":"stdout","text":["  sentiment                                           headline\n","0   neutral  According to Gran , the company has no plans t...\n","1   neutral  Technopolis plans to develop in stages an area...\n","2  negative  The international electronic industry company ...\n","3  positive  With the new production plant the company woul...\n","4  positive  According to the company 's updated strategy f...\n","Total positive: 1363\n","Total negative: 604\n","Total neutral: 2879\n"]}],"source":["df = pd.read_csv('archive/all-data.csv', encoding='latin-1')\n","print(df.head())\n","print(\"Total positive:\", len(df[df['sentiment'] == 'positive']))\n","print(\"Total negative:\", len(df[df['sentiment'] == 'negative']))\n","print(\"Total neutral:\", len(df[df['sentiment'] == 'neutral']))"]},{"cell_type":"markdown","id":"waiting-economy","metadata":{"id":"waiting-economy"},"source":["# Data processing."]},{"cell_type":"code","execution_count":5,"id":"wrong-particular","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wrong-particular","executionInfo":{"status":"ok","timestamp":1704545913159,"user_tz":-60,"elapsed":227,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"cfc91f64-430f-4568-f448-e58c51f33a61"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.series.Series'>\n","10122\n"]}],"source":["# tokenize words in headlines\n","headlines = df['headline']\n","print(type(headlines))\n","tokenizer = tf.keras.preprocessing.text.Tokenizer()\n","tokenizer.fit_on_texts(headlines)\n","print(len(tokenizer.word_index)) # 10000 is a relatively small amount of words so we wont set a cap here"]},{"cell_type":"code","execution_count":6,"id":"processed-coupon","metadata":{"id":"processed-coupon","executionInfo":{"status":"ok","timestamp":1704545923376,"user_tz":-60,"elapsed":275,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}}},"outputs":[],"source":["sequences = tokenizer.texts_to_sequences(headlines)"]},{"cell_type":"code","execution_count":null,"id":"opposite-windsor","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"opposite-windsor","executionInfo":{"status":"ok","timestamp":1704541447126,"user_tz":-60,"elapsed":4,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"4e1269a9-2b64-48d5-bf7a-268614e5026e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Max length: 71\n","(4846, 71)\n","[[  94    5 3498 ...    0    0    0]\n"," [ 840  336    5 ...    0    0    0]\n"," [   1  293  656 ...    0    0    0]\n"," ...\n"," [  42   31  242 ...    0    0    0]\n"," [  30   27    2 ...    0    0    0]\n"," [  27    3   35 ...    0    0    0]]\n","71\n","71\n"]}],"source":["# pad sequences to equal length\n","lengths = map(lambda x: len(x), sequences)\n","max_length = np.max(list(lengths))\n","print(f\"Max length: {max_length}\")\n","sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, padding=\"post\", maxlen=max_length)\n","print(sequences.shape)\n","print(sequences)\n","# check randomly to ensure they are all padded to the correct length\n","print(len(sequences[66]))\n","print(len(sequences[77]))"]},{"cell_type":"markdown","source":["It appears that all are of the same length, and the padding was successful."],"metadata":{"id":"Od7Xl0E1eM4B"},"id":"Od7Xl0E1eM4B"},{"cell_type":"code","execution_count":null,"id":"labeled-bradley","metadata":{"id":"labeled-bradley"},"outputs":[],"source":["# get sentiments (labels), tensorflow requires them to be integers, so need to map them\n","sentiment_mapping = {\n","    \"negative\" : 0,\n","    \"positive\" : 1,\n","    \"neutral\" : 2\n","}\n","y = df['sentiment'].replace(sentiment_mapping)\n","\n","x_train, x_test, y_train, y_test = train_test_split(sequences, y, train_size = 0.7, shuffle = True, random_state = 1)"]},{"cell_type":"code","execution_count":null,"id":"honest-member","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"honest-member","executionInfo":{"status":"ok","timestamp":1704541447126,"user_tz":-60,"elapsed":3,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"a5c4b19c-6f64-4ebb-f46b-190ecc4d2a50"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[5442  510   16 ...    0    0    0]\n"," [  22 1628    4 ...    0    0    0]\n"," [1141  936  136 ...    0    0    0]\n"," ...\n"," [   1  419   16 ...    0    0    0]\n"," [2586  123 3247 ...    0    0    0]\n"," [  30  615  555 ...    0    0    0]]\n","[1, 0, 2, 2, 1, 0, 0, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 0, 1, 2, 1, 2, 1, 1, 2, 1, 2, 2, 1, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 0, 2, 1, 1, 1, 2, 2, 0, 2, 2, 2, 1, 0, 1, 2, 1, 0, 0, 0, 1, 1, 2, 2, 1, 0, 2, 2, 2, 2, 1, 2, 0, 2, 0, 0, 2, 2, 0, 2, 2, 2, 1, 2, 1, 1, 0, 1, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 0, 2, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 2, 1, 1, 0, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 0, 1, 1, 1, 1, 2, 2, 0, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 0, 2, 1, 2, 0, 2, 2, 2, 1, 1, 1, 2, 2, 2, 0, 1, 1, 0, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2, 2, 0, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 0, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 0, 0, 2, 1, 2, 1, 0, 2, 2, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 1, 2, 2, 1, 2, 0, 2, 1, 1, 1, 2, 1, 1, 0, 2, 2, 1, 0, 2, 0, 2, 0, 2, 2, 1, 1, 1, 2, 0, 2, 2, 2, 2, 0, 1, 1, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 2, 1, 1, 1, 2, 0, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 0, 0, 1, 0, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 0, 1, 0, 1, 2, 0, 2, 1, 2, 0, 1, 2, 2, 2, 0, 1, 2, 1, 2, 2, 2, 2, 0, 1, 2, 2, 0, 1, 2, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 2, 0, 2, 0, 2, 1, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 1, 0, 0, 1, 2, 0, 2, 2, 1, 1, 1, 2, 0, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 0, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 0, 2, 1, 2, 0, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 0, 2, 2, 2, 1, 2, 2, 2, 0, 1, 2, 0, 2, 1, 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 1, 2, 2, 0, 1, 2, 2, 2, 1, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 0, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 2, 0, 1, 2, 2, 1, 1, 2, 0, 2, 1, 1, 2, 1, 2, 1, 2, 1, 0, 2, 0, 2, 0, 2, 1, 1, 2, 2, 2, 2, 0, 1, 2, 1, 2, 1, 1, 0, 2, 1, 2, 2, 1, 2, 2, 2, 2, 0, 2, 2, 0, 0, 0, 2, 1, 2, 2, 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 0, 1, 2, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 1, 2, 2, 1, 2, 0, 2, 2, 1, 2, 1, 2, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, 0, 1, 2, 0, 2, 2, 2, 1, 0, 2, 0, 1, 1, 1, 0, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 1, 1, 2, 2, 0, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 0, 2, 1, 2, 1, 2, 2, 2, 0, 2, 0, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 2, 1, 2, 1, 0, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 0, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 0, 2, 2, 2, 2, 2, 1, 2, 0, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 0, 2, 2, 1, 2, 2, 0, 2, 2, 2, 0, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 0, 0, 2, 2, 1, 0, 2, 2, 2, 2, 0, 1, 1, 2, 2, 2, 2, 0, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 0, 0, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 0, 2, 1, 1, 2, 2, 2, 0, 0, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2, 0, 2, 1, 2, 2, 2, 1, 2, 0, 2, 1, 2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 0, 2, 0, 1, 0, 1, 0, 1, 2, 2, 1, 1, 0, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 0, 1, 1, 1, 2, 2, 2, 2, 2, 0, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 0, 0, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 0, 2, 1, 2, 0, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 0, 2, 0, 1, 0, 1, 2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 2, 1, 1, 2, 0, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 0, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 1, 0, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 0, 1, 2, 1, 0, 0, 1, 0, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 0, 2, 0, 2, 1, 2, 2, 2, 1, 0, 2, 0, 2, 2, 0, 1, 1, 2, 2, 0, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 0, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 0, 0, 2, 1, 2, 2, 2, 2, 2, 0, 0, 1, 0, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 0, 1, 2, 1, 2, 2, 2, 2, 2, 2, 0, 1, 1, 2, 1, 0, 0, 2, 1, 1, 1, 2, 2, 2, 2, 0, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 0, 2, 2, 1, 1, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 0, 0, 2, 2, 1, 2, 0, 1, 2, 1, 0, 2, 1, 2, 0, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 0, 0, 2, 2, 1, 1, 2, 1, 2, 2, 0, 2, 0, 2, 2, 1, 2, 2, 2, 0, 2, 1, 1, 2, 1, 2, 2, 2, 1, 1, 2, 0, 2, 1, 2, 1, 2, 2, 0, 2, 2, 1, 2, 1, 2, 2, 2, 0, 0, 0, 2, 2, 0, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 2, 2, 0, 1, 0, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 0, 1, 1, 0, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 0, 2, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 0, 1, 2, 0, 2, 2, 2, 2, 1, 2, 2, 2, 0, 0, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 0, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 0, 2, 1, 2, 1, 2, 1, 2, 0, 2, 2, 2, 0, 1, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 0, 2, 2, 2, 1, 1, 2, 2, 1, 2, 0, 2, 1, 2, 1, 0, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, 0, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 0, 2, 2, 1, 1, 2, 2, 0, 2, 2, 2, 1, 2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2, 0, 1, 2, 2, 1, 0, 1, 2, 2, 1, 2, 2, 0, 2, 2, 2, 2, 1, 2, 0, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 0, 1, 1, 1, 0, 2, 2, 2, 0, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 0, 1, 2, 2, 1, 2, 1, 0, 1, 0, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 0, 1, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 0, 0, 1, 2, 2, 2, 2, 2, 2, 0, 2, 1, 2, 1, 1, 2, 1, 0, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 0, 1, 2, 0, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 0, 1, 2, 2, 0, 2, 1, 2, 2, 2, 2, 2, 0, 0, 1, 1, 0, 2, 2, 2, 2, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 1, 0, 2, 2, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 2, 1, 1, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 0, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 0, 1, 2, 0, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 0, 2, 1, 2, 1, 2, 1, 2, 1, 1, 0, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 0, 0, 2, 0, 2, 2, 2, 1, 0, 2, 1, 0, 2, 0, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 2, 1, 1, 0, 2, 1, 1, 0, 1, 1, 2, 2, 2, 2, 2, 2, 1, 0, 0, 2, 2, 1, 2, 2, 1, 1, 2, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 2, 0, 1, 2, 2, 0, 2, 1, 1, 2, 2, 1, 1, 0, 0, 1, 2, 1, 2, 1, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 1, 2, 1, 1, 2, 1, 2, 2, 2, 0, 1, 1, 2, 2, 0, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 0, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 0, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1, 0, 2, 2, 0, 2, 2, 2, 1, 1, 2, 2, 2, 0, 1, 0, 2, 1, 2, 0, 1, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 2, 2, 1, 2, 2, 2, 0, 1, 1, 2, 2, 2, 2, 2, 0, 2, 1, 2, 2, 2, 0, 1, 1, 2, 1, 2, 0, 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 1, 2, 2, 1, 0, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 0, 2, 0, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, 0, 0, 2, 2, 2, 0, 2, 0, 1, 2, 1, 2, 1, 0, 2, 2, 0, 1, 1, 0, 0, 1, 2, 2, 2, 2, 1, 2, 2, 0, 1, 2, 1, 0, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 1, 2, 1, 0, 2, 2, 2, 2, 1, 2, 1, 2, 2, 0, 2, 2, 2, 2, 1, 1, 1, 2, 0, 0, 2, 0, 2, 2, 1, 1, 2, 1, 0, 1, 1, 2, 1, 1, 2, 0, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 0, 1, 2, 0, 2, 1, 2, 1, 2, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 0, 2, 2, 0, 1, 2, 2, 2, 2, 1, 2, 0, 0, 2, 2, 1, 1, 2, 0, 1, 0, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 0, 1, 2, 0, 2, 1, 2, 2, 2, 0, 2, 1, 1, 1, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 1, 2, 1, 0, 1, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 1, 2, 0, 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2, 2, 1, 2, 2, 0, 2, 2, 2, 2, 1, 2, 2, 0, 2, 2, 1, 1, 0, 0, 0, 2, 0, 0, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 0, 0, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 0, 2, 1, 0, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 0, 1, 2, 2, 1, 1, 2, 1, 2, 0, 2, 0, 2, 2, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 1, 2, 2, 1, 1, 0, 2, 1, 2, 1, 1, 2, 2, 1, 2, 1, 0, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2, 0, 2, 0, 0, 2, 1, 1, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 0, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 1, 2, 1, 1, 2, 2, 2, 0, 1, 2, 1, 2, 0, 1, 1, 2, 2, 0, 2, 1, 1, 2, 2, 2, 2, 0, 0, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 0, 2, 1, 2, 2, 2, 1, 1, 2, 0, 1, 2, 1, 2, 2, 1, 2, 0, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 1, 2, 0, 1, 2, 1, 2, 2, 1, 2, 2, 2, 1, 0, 1, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 0, 1, 1, 2, 2, 1, 1, 1, 0, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 1, 2, 1, 0, 2, 2, 2, 2, 1, 2, 2, 0, 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 0, 2, 2, 0, 0, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 0, 2, 1, 2, 2, 0, 2, 2, 0, 2, 1, 2, 2, 1, 2, 1]\n"]}],"source":["print(x_train)\n","print(list(y_train))"]},{"cell_type":"markdown","source":["First, let's convert words into different integers and encode our sentences based on these integers. In this encoding, there are no specific rules, just encoding. The primary layer of the RNN, the Embedding layer, is crucial. It takes a sequence of sentences with encoded words as input (we need to pad with zeros and/or truncate to ensure uniform size), and it outputs a vector representing a word for a given vector size. Why is this much better than the one-hot encoder used in categorical encoding? Firstly, the one-hot vector would be over 10,000 in length in this case, with only one '1' and the rest '0's, making it impractical. Secondly, all words are equally distant from each other. Training the Embedding allows us to encode words so that words frequently appearing together will be closer in Euclidean distance."],"metadata":{"id":"LPvljF1p_25e"},"id":"LPvljF1p_25e"},{"cell_type":"markdown","id":"continuous-target","metadata":{"id":"continuous-target"},"source":["# RNN Basics"]},{"cell_type":"markdown","source":["Let's illustrate a simple RNN model, train it, and observe the results."],"metadata":{"id":"rRkZQGNUgmDI"},"id":"rRkZQGNUgmDI"},{"cell_type":"markdown","source":["<img src='https://drive.google.com/uc?id=1cCqTXurPJYd7BwyIpfrsOo_1FU0kxx0U' width='90%'>\n","\n","<br><br>\n","\n","$$h_t = f_W(h_{t-1}, x_t)$$\n","\n",">The same function $f$ and parameters $W$ are used at each step\n","\n","1. input at step $t$:\n"," - $x_t$\n","2. hidden state update:\n"," - $h_t = \\tanh(W_{hh}^Th_{t-1} + W_{xh}^Tx_t + b_h)$\n","3. output:\n"," - $\\hat{y}t=W^T{hy}h_t + b_y$\n","\n","So, we update all these weights during training.\n"],"metadata":{"id":"vfzNj5GjgKJg"},"id":"vfzNj5GjgKJg"},{"cell_type":"markdown","source":["Before training the baseline model, we need to discuss all the parameters. Firstly, in the Embedding layer, we need to set the size of the vector representing words. In one-hot encoding, this would be the size of the vocabulary, but now we want to reduce it. Of course, a larger vector will better represent a word, but it will also slow down the network training. There is no fixed number that is good for choosing the dimension for any dataset. Considering that Word2Vec uses 300 dimensions for a much larger vocabulary in Google News, it doesn't make sense to go beyond 300. We will try 50 and 100 dimensions and compare effectiveness defined as: accuracy - 0.001*seconds."],"metadata":{"id":"soAoDHKvjPnX"},"id":"soAoDHKvjPnX"},{"cell_type":"markdown","source":["We will use ADAM to avoid getting stuck in a local minimum, which is a common issue with other optimizers like SGD."],"metadata":{"id":"4LMp3-Y5cwWw"},"id":"4LMp3-Y5cwWw"},{"cell_type":"markdown","source":["# 50-dimensional vector."],"metadata":{"id":"WB2hD_dzsm-Z"},"id":"WB2hD_dzsm-Z"},{"cell_type":"code","source":["model = tf.keras.models.Sequential()\n","model.add(tf.keras.layers.Embedding(input_dim=10123,\n","                                    output_dim=50,\n","                                    input_length=x_train.shape[1]))\n","model.add(tf.keras.layers.SimpleRNN(50))\n","model.add(tf.keras.layers.Dense(3, activation='softmax'))\n","\n","model.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer='adam',\n","    metrics=['accuracy']\n",")"],"metadata":{"id":"zIpjtsRyivmn"},"id":"zIpjtsRyivmn","execution_count":null,"outputs":[]},{"cell_type":"code","source":["start_time = time.time()\n","\n","history = model.fit(\n","    x_train,\n","    y_train,\n","    validation_split=0.2,\n","    batch_size=32,\n","    epochs=10,\n",")\n","\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print(\"Elapsed time: \", elapsed_time)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DIHKtTNdmS7s","executionInfo":{"status":"ok","timestamp":1704369541073,"user_tz":-60,"elapsed":143689,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"878bcbf8-5ed5-4012-d68e-9904ddd94f64"},"id":"DIHKtTNdmS7s","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","85/85 [==============================] - 20s 213ms/step - loss: 0.9200 - accuracy: 0.6052 - val_loss: 0.9586 - val_accuracy: 0.5700\n","Epoch 2/10\n","85/85 [==============================] - 13s 157ms/step - loss: 0.9163 - accuracy: 0.6052 - val_loss: 0.9584 - val_accuracy: 0.5700\n","Epoch 3/10\n","85/85 [==============================] - 9s 104ms/step - loss: 0.9156 - accuracy: 0.6052 - val_loss: 0.9667 - val_accuracy: 0.5700\n","Epoch 4/10\n","85/85 [==============================] - 9s 101ms/step - loss: 0.9157 - accuracy: 0.6052 - val_loss: 0.9693 - val_accuracy: 0.5700\n","Epoch 5/10\n","85/85 [==============================] - 7s 78ms/step - loss: 0.9082 - accuracy: 0.6049 - val_loss: 0.9851 - val_accuracy: 0.4786\n","Epoch 6/10\n","85/85 [==============================] - 9s 101ms/step - loss: 0.8956 - accuracy: 0.6023 - val_loss: 0.9732 - val_accuracy: 0.5700\n","Epoch 7/10\n","85/85 [==============================] - 6s 76ms/step - loss: 0.8948 - accuracy: 0.6008 - val_loss: 0.9708 - val_accuracy: 0.5700\n","Epoch 8/10\n","85/85 [==============================] - 8s 100ms/step - loss: 0.8905 - accuracy: 0.6012 - val_loss: 0.9845 - val_accuracy: 0.5700\n","Epoch 9/10\n","85/85 [==============================] - 7s 78ms/step - loss: 0.8896 - accuracy: 0.5923 - val_loss: 0.9707 - val_accuracy: 0.5700\n","Epoch 10/10\n","85/85 [==============================] - 8s 96ms/step - loss: 0.8854 - accuracy: 0.6034 - val_loss: 0.9692 - val_accuracy: 0.5700\n","Elapsed time:  143.57347583770752\n"]}]},{"cell_type":"code","source":["_, acc = model.evaluate(x_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S9z8H0ernLkV","executionInfo":{"status":"ok","timestamp":1704369565424,"user_tz":-60,"elapsed":553,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"a4b57bdb-fcf1-44d7-8796-d0d84d131e66"},"id":"S9z8H0ernLkV","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["46/46 [==============================] - 0s 9ms/step - loss: 0.9325 - accuracy: 0.5846\n"]}]},{"cell_type":"code","source":["acc - 0.001*elapsed_time"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M23zvHDVnVe5","executionInfo":{"status":"ok","timestamp":1704369572328,"user_tz":-60,"elapsed":3,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"e95764b7-411d-4e9f-ea24-9026bd2db240"},"id":"M23zvHDVnVe5","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4410207738876343"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["As we can see, the accuracy on the validation set hardly changes. Let's implement early stopping to save time."],"metadata":{"id":"nzKA5UYubowZ"},"id":"nzKA5UYubowZ"},{"cell_type":"markdown","source":["# Early stopping"],"metadata":{"id":"RvRWkN5_cpRg"},"id":"RvRWkN5_cpRg"},{"cell_type":"code","source":["model = tf.keras.models.Sequential()\n","model.add(tf.keras.layers.Embedding(input_dim=10123,\n","                                    output_dim=50,\n","                                    input_length=x_train.shape[1]))\n","model.add(tf.keras.layers.SimpleRNN(50))\n","model.add(tf.keras.layers.Dense(3, activation='softmax'))\n","\n","model.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer='adam',\n","    metrics=['accuracy']\n",")"],"metadata":{"id":"aPeXVp6-b2zQ"},"id":"aPeXVp6-b2zQ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# zaustavljamo treniranje mreže ako 3 uzastopne epohe nema poboljšanja gubitka na skupu za validaciju\n","callback_ES = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","\n","start_time = time.time()\n","\n","history = model.fit(\n","    x_train,\n","    y_train,\n","    validation_split=0.2,\n","    batch_size=32,\n","    epochs=10,\n","    callbacks=[callback_ES]\n",")\n","\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print(\"Elapsed time: \", elapsed_time)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YPouSlPUb5MJ","executionInfo":{"status":"ok","timestamp":1704371930689,"user_tz":-60,"elapsed":41833,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"b149be80-efdb-46f4-8bb8-8f891ea37f1d"},"id":"YPouSlPUb5MJ","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","85/85 [==============================] - 15s 146ms/step - loss: 0.8783 - accuracy: 0.6159 - val_loss: 0.8674 - val_accuracy: 0.5817\n","Epoch 2/10\n","85/85 [==============================] - 9s 109ms/step - loss: 0.6248 - accuracy: 0.7564 - val_loss: 0.9022 - val_accuracy: 0.5965\n","Epoch 3/10\n","85/85 [==============================] - 11s 128ms/step - loss: 0.4807 - accuracy: 0.8120 - val_loss: 1.0489 - val_accuracy: 0.6421\n","Epoch 4/10\n","85/85 [==============================] - 7s 77ms/step - loss: 0.3675 - accuracy: 0.8669 - val_loss: 1.0735 - val_accuracy: 0.6377\n","Elapsed time:  41.82280445098877\n"]}]},{"cell_type":"code","source":["_, acc = model.evaluate(x_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yE0pi5FVcXdU","executionInfo":{"status":"ok","timestamp":1704371931481,"user_tz":-60,"elapsed":565,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"1d20d739-5f1e-48e4-9aab-1aaaf6fd1d9b"},"id":"yE0pi5FVcXdU","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["46/46 [==============================] - 0s 7ms/step - loss: 0.8350 - accuracy: 0.6059\n"]}]},{"cell_type":"code","source":["acc - 0.001*elapsed_time"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yw0cVgBXcYcZ","executionInfo":{"status":"ok","timestamp":1704371931482,"user_tz":-60,"elapsed":4,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"6f3ad1b4-3d27-40c6-e7d5-3a7c172e8dff"},"id":"yw0cVgBXcYcZ","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5640919075012207"]},"metadata":{},"execution_count":49}]},{"cell_type":"markdown","source":["According to our effectiveness measure, the early stopping model is much better."],"metadata":{"id":"e6POmS8QcfyI"},"id":"e6POmS8QcfyI"},{"cell_type":"markdown","source":["# 100-dimensional vector"],"metadata":{"id":"FzOE5sxItI_n"},"id":"FzOE5sxItI_n"},{"cell_type":"code","source":["model = tf.keras.models.Sequential()\n","model.add(tf.keras.layers.Embedding(input_dim=10123,\n","                                    output_dim=100,\n","                                    input_length=x_train.shape[1]))\n","model.add(tf.keras.layers.SimpleRNN(100))\n","model.add(tf.keras.layers.Dense(3, activation='softmax'))\n","\n","model.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer='adam',\n","    metrics=['accuracy']\n",")"],"metadata":{"id":"9siF2brJnfYK"},"id":"9siF2brJnfYK","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# zaustavljamo treniranje mreže ako 3 uzastopne epohe nema poboljšanja gubitka na skupu za validaciju\n","callback_ES = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","\n","start_time = time.time()\n","\n","history = model.fit(\n","    x_train,\n","    y_train,\n","    validation_split=0.2,\n","    batch_size=32,\n","    epochs=10,\n","    callbacks=[callback_ES]\n",")\n","\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print(\"Elapsed time: \", elapsed_time)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MDodVm_mna4x","executionInfo":{"status":"ok","timestamp":1704371987071,"user_tz":-60,"elapsed":55250,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"5b5638d6-b1de-4092-91c8-caf439615690"},"id":"MDodVm_mna4x","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","85/85 [==============================] - 15s 153ms/step - loss: 0.9225 - accuracy: 0.6049 - val_loss: 0.9857 - val_accuracy: 0.5700\n","Epoch 2/10\n","85/85 [==============================] - 10s 121ms/step - loss: 0.9227 - accuracy: 0.6052 - val_loss: 0.9623 - val_accuracy: 0.5714\n","Epoch 3/10\n","85/85 [==============================] - 8s 93ms/step - loss: 0.9226 - accuracy: 0.5916 - val_loss: 0.9547 - val_accuracy: 0.5700\n","Epoch 4/10\n","85/85 [==============================] - 7s 84ms/step - loss: 0.9025 - accuracy: 0.5905 - val_loss: 1.0103 - val_accuracy: 0.5700\n","Epoch 5/10\n","85/85 [==============================] - 7s 88ms/step - loss: 0.9103 - accuracy: 0.5986 - val_loss: 0.9732 - val_accuracy: 0.5700\n","Epoch 6/10\n","85/85 [==============================] - 8s 90ms/step - loss: 0.8448 - accuracy: 0.6439 - val_loss: 0.9918 - val_accuracy: 0.5331\n","Elapsed time:  55.365785360336304\n"]}]},{"cell_type":"code","source":["_, acc = model.evaluate(x_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DUBN7HainoqG","executionInfo":{"status":"ok","timestamp":1704372015392,"user_tz":-60,"elapsed":28325,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"a3bc7ae7-6a24-428f-afbd-afb1074bb7d0"},"id":"DUBN7HainoqG","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["46/46 [==============================] - 0s 7ms/step - loss: 0.9255 - accuracy: 0.5846\n"]}]},{"cell_type":"code","source":["acc - 0.001*elapsed_time"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kcWH99a3ntI7","executionInfo":{"status":"ok","timestamp":1704372015739,"user_tz":-60,"elapsed":360,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"c7827644-f116-48bf-a188-b66a64d77c89"},"id":"kcWH99a3ntI7","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5292284643650055"]},"metadata":{},"execution_count":53}]},{"cell_type":"markdown","source":["As we can see in this attempt, the 100-dimensional vector yielded worse results. Therefore, I conclude that the difference is not significant, and we can opt for the 50-dimensional vector. It's likely that we could even use a vector of smaller dimensions due to the small vocabulary."],"metadata":{"id":"_qzD68_jXCpl"},"id":"_qzD68_jXCpl"},{"cell_type":"markdown","source":["We notice that these accuracies hover around 59 percent. At first glance, it may not seem like a terrible result. However, a trivial network that only predicts \"neutral\" would give us 59 percent accuracy since we have approximately 59 percent neutral news in the data. Therefore, we definitely want higher accuracy than this."],"metadata":{"id":"ix7KYOF9fnHt"},"id":"ix7KYOF9fnHt"},{"cell_type":"markdown","source":["# GRU"],"metadata":{"id":"QHRfDOMbDjfA"},"id":"QHRfDOMbDjfA"},{"cell_type":"markdown","source":["Our model is learning very slowly, and it seems that after a few iterations it's not improving, which leads to early stopping. We used a simple RNN, so we likely encountered the issue of vanishing gradients. The vanishing gradient problem arises because of the way weights are computed in the network: in later iterations, \"older\" weights stop training (\"backpropagation\" weakly updates older weights due to very small derivatives – the issue arises if using sigmoid or hyperbolic tangent activation functions). Let's change the model to a GRU now.\n","\n","What is a GRU?\n","\n","<br>\n","\n","<img src='https://miro.medium.com/v2/resize:fit:720/format:webp/1*6eNTqLzQ08AABo-STFNiBw.png' width='90%'>\n","\n","<br>\n"],"metadata":{"id":"8eck_RmPAxqC"},"id":"8eck_RmPAxqC"},{"cell_type":"code","source":["model = tf.keras.models.Sequential()\n","model.add(tf.keras.layers.Embedding(input_dim=10123,\n","                                    output_dim=50,\n","                                    input_length=x_train.shape[1]))\n","model.add(tf.keras.layers.GRU(256, activation='tanh', return_sequences=True))\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(3, activation='softmax'))\n","\n","model.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer='adam',\n","    metrics=['accuracy']\n",")"],"metadata":{"id":"cZnEyiFbDfDZ"},"id":"cZnEyiFbDfDZ","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["It's important to emphasize the use of \"return_sequences=True,\" which allows us to \"return\" a sequence of all hidden states (these are just the outputs in the sequence)."],"metadata":{"id":"1hMs4o0zm4U7"},"id":"1hMs4o0zm4U7"},{"cell_type":"code","source":["# zaustavljamo treniranje mreže ako 3 uzastopne epohe nema poboljšanja gubitka na skupu za validaciju\n","callback_ES = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","\n","start_time = time.time()\n","\n","history = model.fit(\n","    x_train,\n","    y_train,\n","    validation_split=0.2,\n","    batch_size=32,\n","    epochs=10,\n","    callbacks=[callback_ES]\n",")\n","\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print(\"Elapsed time: \", elapsed_time)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yvqllQsdDoyh","executionInfo":{"status":"ok","timestamp":1704448958327,"user_tz":-60,"elapsed":33634,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"4cb9ad81-6bcd-4a60-bcec-bad63249bccc"},"id":"yvqllQsdDoyh","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","85/85 [==============================] - 15s 133ms/step - loss: 0.8511 - accuracy: 0.6273 - val_loss: 0.8041 - val_accuracy: 0.6377\n","Epoch 2/10\n","85/85 [==============================] - 8s 93ms/step - loss: 0.5468 - accuracy: 0.7737 - val_loss: 0.7702 - val_accuracy: 0.6672\n","Epoch 3/10\n","85/85 [==============================] - 4s 50ms/step - loss: 0.2370 - accuracy: 0.9090 - val_loss: 1.0677 - val_accuracy: 0.6804\n","Epoch 4/10\n","85/85 [==============================] - 3s 30ms/step - loss: 0.0600 - accuracy: 0.9827 - val_loss: 1.3067 - val_accuracy: 0.6745\n","Epoch 5/10\n","85/85 [==============================] - 3s 37ms/step - loss: 0.0312 - accuracy: 0.9923 - val_loss: 1.2007 - val_accuracy: 0.6922\n","Elapsed time:  33.35904788970947\n"]}]},{"cell_type":"code","source":["_, acc = model.evaluate(x_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8GYR3ExaDqNg","executionInfo":{"status":"ok","timestamp":1704448969158,"user_tz":-60,"elapsed":1253,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"f2e8efea-c249-408e-ba5b-c282bbb0921b"},"id":"8GYR3ExaDqNg","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["46/46 [==============================] - 0s 7ms/step - loss: 0.6875 - accuracy: 0.7125\n"]}]},{"cell_type":"code","source":["acc - 0.001*elapsed_time"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pGYKPedQDrZg","executionInfo":{"status":"ok","timestamp":1704448969158,"user_tz":-60,"elapsed":3,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"ff5acc96-2212-4226-e3ac-c7c45dd7acee"},"id":"pGYKPedQDrZg","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6791581540107727"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["As we can see, these are significantly better results. Let's check if it would be better without early stopping."],"metadata":{"id":"Ege3jlrAE28f"},"id":"Ege3jlrAE28f"},{"cell_type":"markdown","source":["# GRU without early stopping"],"metadata":{"id":"67HF7BMQE94H"},"id":"67HF7BMQE94H"},{"cell_type":"code","source":["model = tf.keras.models.Sequential()\n","model.add(tf.keras.layers.Embedding(input_dim=10123,\n","                                    output_dim=50,\n","                                    input_length=x_train.shape[1]))\n","model.add(tf.keras.layers.GRU(256, activation='tanh', return_sequences=True))\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(3, activation='softmax'))\n","\n","model.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer='adam',\n","    metrics=['accuracy']\n",")"],"metadata":{"id":"ICd7_CzEE9W4"},"id":"ICd7_CzEE9W4","execution_count":null,"outputs":[]},{"cell_type":"code","source":["start_time = time.time()\n","\n","history = model.fit(\n","    x_train,\n","    y_train,\n","    validation_split=0.2,\n","    batch_size=32,\n","    epochs=10,\n",")\n","\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print(\"Elapsed time: \", elapsed_time)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M1g45seKFEo3","executionInfo":{"status":"ok","timestamp":1704449082662,"user_tz":-60,"elapsed":27224,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"7cdcf65e-45e0-4350-ec9c-66256362cfeb"},"id":"M1g45seKFEo3","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","85/85 [==============================] - 11s 102ms/step - loss: 0.8430 - accuracy: 0.6314 - val_loss: 0.8072 - val_accuracy: 0.6303\n","Epoch 2/10\n","85/85 [==============================] - 4s 50ms/step - loss: 0.5497 - accuracy: 0.7726 - val_loss: 0.7873 - val_accuracy: 0.6804\n","Epoch 3/10\n","85/85 [==============================] - 2s 25ms/step - loss: 0.2229 - accuracy: 0.9156 - val_loss: 0.8842 - val_accuracy: 0.6907\n","Epoch 4/10\n","85/85 [==============================] - 1s 18ms/step - loss: 0.0751 - accuracy: 0.9794 - val_loss: 1.2013 - val_accuracy: 0.6981\n","Epoch 5/10\n","85/85 [==============================] - 1s 17ms/step - loss: 0.0345 - accuracy: 0.9930 - val_loss: 1.3424 - val_accuracy: 0.6789\n","Epoch 6/10\n","85/85 [==============================] - 2s 21ms/step - loss: 0.0172 - accuracy: 0.9941 - val_loss: 1.4251 - val_accuracy: 0.6878\n","Epoch 7/10\n","85/85 [==============================] - 2s 24ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 1.9501 - val_accuracy: 0.6672\n","Epoch 8/10\n","85/85 [==============================] - 1s 14ms/step - loss: 0.0077 - accuracy: 0.9985 - val_loss: 1.9655 - val_accuracy: 0.6996\n","Epoch 9/10\n","85/85 [==============================] - 1s 15ms/step - loss: 6.2887e-04 - accuracy: 1.0000 - val_loss: 2.3835 - val_accuracy: 0.6848\n","Epoch 10/10\n","85/85 [==============================] - 1s 10ms/step - loss: 1.3404e-04 - accuracy: 1.0000 - val_loss: 2.5748 - val_accuracy: 0.6892\n","Elapsed time:  27.168657779693604\n"]}]},{"cell_type":"code","source":["_, acc = model.evaluate(x_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8z4uyuygFHS_","executionInfo":{"status":"ok","timestamp":1704449083024,"user_tz":-60,"elapsed":376,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"e7cde8bf-a280-4fd7-c905-b8345d33d5e6"},"id":"8z4uyuygFHS_","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["46/46 [==============================] - 0s 4ms/step - loss: 2.2793 - accuracy: 0.7407\n"]}]},{"cell_type":"code","source":["acc - 0.001*elapsed_time"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UzBVdVsMFHNe","executionInfo":{"status":"ok","timestamp":1704449083024,"user_tz":-60,"elapsed":3,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"12636d5b-11e2-4c4e-ce19-51555d7f5ecf"},"id":"UzBVdVsMFHNe","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7135466074943543"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["The result is better when we removed early stopping."],"metadata":{"id":"GNSgNo0kKK_2"},"id":"GNSgNo0kKK_2"},{"cell_type":"markdown","source":["# LSTM"],"metadata":{"id":"V9VQF6NEKSee"},"id":"V9VQF6NEKSee"},{"cell_type":"markdown","source":["Let's now try with an LSTM. First, let's look at the structure of an LSTM.\n","\n","<br>\n","\n","<img src='https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png' width='90%'>\n","\n","<br>"],"metadata":{"id":"EgVfJaVeKR9G"},"id":"EgVfJaVeKR9G"},{"cell_type":"code","source":["model = tf.keras.models.Sequential()\n","model.add(tf.keras.layers.Embedding(input_dim=10123,\n","                                    output_dim=50,\n","                                    input_length=x_train.shape[1]))\n","model.add(tf.keras.layers.LSTM(50, return_sequences=True))\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(3, activation='softmax'))\n","\n","model.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer='adam',\n","    metrics=['accuracy']\n",")"],"metadata":{"id":"_BdMJH9hKaS5"},"id":"_BdMJH9hKaS5","execution_count":null,"outputs":[]},{"cell_type":"code","source":["start_time = time.time()\n","\n","history = model.fit(\n","    x_train,\n","    y_train,\n","    validation_split=0.2,\n","    batch_size=32,\n","    epochs=10,\n",")\n","\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print(\"Elapsed time: \", elapsed_time)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kX-4xAm9KdGO","executionInfo":{"status":"ok","timestamp":1704541488592,"user_tz":-60,"elapsed":40529,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"2b1be7e4-eb9a-4103-ffaa-f93bc837dd39"},"id":"kX-4xAm9KdGO","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","85/85 [==============================] - 18s 178ms/step - loss: 0.8502 - accuracy: 0.6299 - val_loss: 0.8337 - val_accuracy: 0.6436\n","Epoch 2/10\n","85/85 [==============================] - 5s 59ms/step - loss: 0.5680 - accuracy: 0.7663 - val_loss: 0.8172 - val_accuracy: 0.6215\n","Epoch 3/10\n","85/85 [==============================] - 5s 63ms/step - loss: 0.3090 - accuracy: 0.8765 - val_loss: 0.8645 - val_accuracy: 0.6951\n","Epoch 4/10\n","85/85 [==============================] - 3s 31ms/step - loss: 0.1043 - accuracy: 0.9606 - val_loss: 1.1920 - val_accuracy: 0.6951\n","Epoch 5/10\n","85/85 [==============================] - 3s 31ms/step - loss: 0.0436 - accuracy: 0.9871 - val_loss: 1.2984 - val_accuracy: 0.6627\n","Epoch 6/10\n","85/85 [==============================] - 1s 18ms/step - loss: 0.0269 - accuracy: 0.9915 - val_loss: 1.4755 - val_accuracy: 0.6760\n","Epoch 7/10\n","85/85 [==============================] - 1s 15ms/step - loss: 0.0267 - accuracy: 0.9937 - val_loss: 1.5564 - val_accuracy: 0.6966\n","Epoch 8/10\n","85/85 [==============================] - 1s 11ms/step - loss: 0.0125 - accuracy: 0.9971 - val_loss: 1.5426 - val_accuracy: 0.6760\n","Epoch 9/10\n","85/85 [==============================] - 1s 9ms/step - loss: 0.0067 - accuracy: 0.9985 - val_loss: 1.8185 - val_accuracy: 0.6804\n","Epoch 10/10\n","85/85 [==============================] - 2s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 2.2041 - val_accuracy: 0.6922\n","Elapsed time:  40.371262073516846\n"]}]},{"cell_type":"code","source":["_, acc = model.evaluate(x_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZyRqGy9UKeP2","executionInfo":{"status":"ok","timestamp":1704541489085,"user_tz":-60,"elapsed":497,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"74eee92a-5da4-49aa-d335-79e42e6a267a"},"id":"ZyRqGy9UKeP2","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["46/46 [==============================] - 0s 6ms/step - loss: 1.9230 - accuracy: 0.7345\n"]}]},{"cell_type":"code","source":["acc - 0.001*elapsed_time"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OxWtMdQIKfQm","executionInfo":{"status":"ok","timestamp":1704541489086,"user_tz":-60,"elapsed":5,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"aa22a6a1-ef75-4e93-9361-8f6822ff5f01"},"id":"OxWtMdQIKfQm","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6941541800498963"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["It's a bit slower than GRU and the results are similar."],"metadata":{"id":"xCbvUzyms98d"},"id":"xCbvUzyms98d"},{"cell_type":"markdown","source":["# Bidirectional LSTM"],"metadata":{"id":"Tt5sK4kfPqyK"},"id":"Tt5sK4kfPqyK"},{"cell_type":"markdown","source":["<img src='https://production-media.paperswithcode.com/methods/Screen_Shot_2020-05-25_at_8.54.27_PM.png\n","' width='90%'>\n","\n","<br>\n","\n","It improves the context of the sentence because we know what happened before and after a given word."],"metadata":{"id":"dQuvmzs1tONV"},"id":"dQuvmzs1tONV"},{"cell_type":"code","source":["model = tf.keras.models.Sequential()\n","model.add(tf.keras.layers.Embedding(input_dim=10123,\n","                                    output_dim=50,\n","                                    input_length=x_train.shape[1]))\n","model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50, return_sequences=True)))\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(3, activation='softmax'))\n","\n","model.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer='adam',\n","    metrics=['accuracy']\n",")"],"metadata":{"id":"tusYgzV4PcGS"},"id":"tusYgzV4PcGS","execution_count":null,"outputs":[]},{"cell_type":"code","source":["start_time = time.time()\n","\n","history = model.fit(\n","    x_train,\n","    y_train,\n","    validation_split=0.2,\n","    batch_size=32,\n","    epochs=10,\n",")\n","\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print(\"Elapsed time: \", elapsed_time)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-aqj7faGPaTS","executionInfo":{"status":"ok","timestamp":1704451829391,"user_tz":-60,"elapsed":31813,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"0a286ca7-e217-46e5-f5a5-f04304879eb3"},"id":"-aqj7faGPaTS","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","85/85 [==============================] - 11s 88ms/step - loss: 0.8590 - accuracy: 0.6285 - val_loss: 0.8447 - val_accuracy: 0.6451\n","Epoch 2/10\n","85/85 [==============================] - 5s 63ms/step - loss: 0.5686 - accuracy: 0.7685 - val_loss: 0.7884 - val_accuracy: 0.6672\n","Epoch 3/10\n","85/85 [==============================] - 3s 36ms/step - loss: 0.2446 - accuracy: 0.9101 - val_loss: 0.8609 - val_accuracy: 0.7128\n","Epoch 4/10\n","85/85 [==============================] - 3s 36ms/step - loss: 0.0777 - accuracy: 0.9779 - val_loss: 1.1071 - val_accuracy: 0.7158\n","Epoch 5/10\n","85/85 [==============================] - 2s 19ms/step - loss: 0.0474 - accuracy: 0.9871 - val_loss: 1.1526 - val_accuracy: 0.7010\n","Epoch 6/10\n","85/85 [==============================] - 2s 19ms/step - loss: 0.0226 - accuracy: 0.9959 - val_loss: 1.3842 - val_accuracy: 0.6922\n","Epoch 7/10\n","85/85 [==============================] - 2s 27ms/step - loss: 0.0109 - accuracy: 0.9985 - val_loss: 1.4793 - val_accuracy: 0.6819\n","Epoch 8/10\n","85/85 [==============================] - 2s 19ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 1.6862 - val_accuracy: 0.6996\n","Epoch 9/10\n","85/85 [==============================] - 1s 16ms/step - loss: 0.0059 - accuracy: 0.9993 - val_loss: 1.7862 - val_accuracy: 0.6848\n","Epoch 10/10\n","85/85 [==============================] - 1s 15ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 1.7123 - val_accuracy: 0.6937\n","Elapsed time:  32.15957164764404\n"]}]},{"cell_type":"code","source":["_, acc = model.evaluate(x_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rUuKOkDpPl36","executionInfo":{"status":"ok","timestamp":1704451830141,"user_tz":-60,"elapsed":374,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"6075535d-8d8e-4798-a809-5363d128a1b6"},"id":"rUuKOkDpPl36","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["46/46 [==============================] - 0s 4ms/step - loss: 1.4706 - accuracy: 0.7366\n"]}]},{"cell_type":"code","source":["acc - 0.001*elapsed_time"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NtLUi20bPmfJ","executionInfo":{"status":"ok","timestamp":1704451830141,"user_tz":-60,"elapsed":2,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"55325f37-c0f8-4058-a30a-95ef2518679b"},"id":"NtLUi20bPmfJ","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.704429144859314"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","source":["There is no significant improvement."],"metadata":{"id":"vqx1WvK3tDuQ"},"id":"vqx1WvK3tDuQ"},{"cell_type":"markdown","source":["# Bidirectional LSTM with dropout"],"metadata":{"id":"iNgHLShZQEv8"},"id":"iNgHLShZQEv8"},{"cell_type":"markdown","source":["Apart from implementing dropout, we will also save the model that had the best accuracy on validation and try applying it to the test set."],"metadata":{"id":"Bdq9TQ02uNJe"},"id":"Bdq9TQ02uNJe"},{"cell_type":"code","source":["checkpoint_LSTM = tf.keras.callbacks.ModelCheckpoint('LSTM_best_val_acc.h5',\n","                                                     monitor='val_accuracy',\n","                                                     verbose=1,\n","                                                     save_best_only=True,\n","                                                     mode='max')"],"metadata":{"id":"7HRI0A3mRHDR"},"id":"7HRI0A3mRHDR","execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = tf.keras.models.Sequential()\n","model.add(tf.keras.layers.Embedding(input_dim=10123,\n","                                    output_dim=50,\n","                                    input_length=x_train.shape[1]))\n","model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50, return_sequences=True)))\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dropout(0.3))\n","model.add(tf.keras.layers.Dense(3, activation='softmax'))\n","\n","model.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer='adam',\n","    metrics=['accuracy']\n",")"],"metadata":{"id":"7EQvXt1kPv8q"},"id":"7EQvXt1kPv8q","execution_count":null,"outputs":[]},{"cell_type":"code","source":["start_time = time.time()\n","\n","history = model.fit(\n","    x_train,\n","    y_train,\n","    validation_split=0.2,\n","    batch_size=32,\n","    epochs=10,\n","    callbacks=[checkpoint_LSTM]\n",")\n","\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print(\"Elapsed time: \", elapsed_time)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2l72JgWrQCOi","executionInfo":{"status":"ok","timestamp":1704452264462,"user_tz":-60,"elapsed":31662,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"d8c7750c-e413-4f86-e1cc-690de1076b6e"},"id":"2l72JgWrQCOi","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","85/85 [==============================] - ETA: 0s - loss: 0.8579 - accuracy: 0.6222\n","Epoch 1: val_accuracy improved from -inf to 0.63623, saving model to LSTM_best_val_acc.h5\n","85/85 [==============================] - 14s 113ms/step - loss: 0.8579 - accuracy: 0.6222 - val_loss: 0.8056 - val_accuracy: 0.6362\n","Epoch 2/10\n"," 1/85 [..............................] - ETA: 8s - loss: 0.5613 - accuracy: 0.7500"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["82/85 [===========================>..] - ETA: 0s - loss: 0.5616 - accuracy: 0.7683\n","Epoch 2: val_accuracy improved from 0.63623 to 0.67599, saving model to LSTM_best_val_acc.h5\n","85/85 [==============================] - 5s 52ms/step - loss: 0.5603 - accuracy: 0.7667 - val_loss: 0.8052 - val_accuracy: 0.6760\n","Epoch 3/10\n","85/85 [==============================] - ETA: 0s - loss: 0.2326 - accuracy: 0.9134\n","Epoch 3: val_accuracy improved from 0.67599 to 0.68483, saving model to LSTM_best_val_acc.h5\n","85/85 [==============================] - 3s 37ms/step - loss: 0.2326 - accuracy: 0.9134 - val_loss: 0.9850 - val_accuracy: 0.6848\n","Epoch 4/10\n","83/85 [============================>.] - ETA: 0s - loss: 0.0724 - accuracy: 0.9748\n","Epoch 4: val_accuracy improved from 0.68483 to 0.69072, saving model to LSTM_best_val_acc.h5\n","85/85 [==============================] - 2s 25ms/step - loss: 0.0715 - accuracy: 0.9753 - val_loss: 1.1538 - val_accuracy: 0.6907\n","Epoch 5/10\n","85/85 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9912\n","Epoch 5: val_accuracy improved from 0.69072 to 0.71134, saving model to LSTM_best_val_acc.h5\n","85/85 [==============================] - 1s 17ms/step - loss: 0.0316 - accuracy: 0.9912 - val_loss: 1.2167 - val_accuracy: 0.7113\n","Epoch 6/10\n","85/85 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9971\n","Epoch 6: val_accuracy did not improve from 0.71134\n","85/85 [==============================] - 2s 18ms/step - loss: 0.0159 - accuracy: 0.9971 - val_loss: 1.6122 - val_accuracy: 0.6966\n","Epoch 7/10\n","85/85 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9967\n","Epoch 7: val_accuracy improved from 0.71134 to 0.71429, saving model to LSTM_best_val_acc.h5\n","85/85 [==============================] - 1s 14ms/step - loss: 0.0153 - accuracy: 0.9967 - val_loss: 1.6497 - val_accuracy: 0.7143\n","Epoch 8/10\n","85/85 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9978\n","Epoch 8: val_accuracy improved from 0.71429 to 0.71576, saving model to LSTM_best_val_acc.h5\n","85/85 [==============================] - 2s 18ms/step - loss: 0.0101 - accuracy: 0.9978 - val_loss: 1.5319 - val_accuracy: 0.7158\n","Epoch 9/10\n","82/85 [===========================>..] - ETA: 0s - loss: 0.0029 - accuracy: 0.9992\n","Epoch 9: val_accuracy did not improve from 0.71576\n","85/85 [==============================] - 1s 13ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 1.9115 - val_accuracy: 0.7054\n","Epoch 10/10\n","85/85 [==============================] - ETA: 0s - loss: 4.5194e-04 - accuracy: 1.0000\n","Epoch 10: val_accuracy did not improve from 0.71576\n","85/85 [==============================] - 1s 15ms/step - loss: 4.5194e-04 - accuracy: 1.0000 - val_loss: 2.1202 - val_accuracy: 0.7010\n","Elapsed time:  31.557350158691406\n"]}]},{"cell_type":"code","source":["best_LSTM = tf.keras.models.load_model('LSTM_best_val_acc.h5')"],"metadata":{"id":"Sx4OwvdkRZyh"},"id":"Sx4OwvdkRZyh","execution_count":null,"outputs":[]},{"cell_type":"code","source":["_, acc = best_LSTM.evaluate(x_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M-xHbvjRP_2S","executionInfo":{"status":"ok","timestamp":1704452300451,"user_tz":-60,"elapsed":1320,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"4074463d-5266-4af3-be86-ae02963818fc"},"id":"M-xHbvjRP_2S","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["46/46 [==============================] - 1s 6ms/step - loss: 1.3697 - accuracy: 0.7366\n"]}]},{"cell_type":"code","source":["acc - 0.001*elapsed_time"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FQqT4PoRQAmq","executionInfo":{"status":"ok","timestamp":1704452302112,"user_tz":-60,"elapsed":267,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"a2689480-da12-406e-9024-606693377454"},"id":"FQqT4PoRQAmq","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7050313663482666"]},"metadata":{},"execution_count":56}]},{"cell_type":"markdown","source":["Dropout did not help."],"metadata":{"id":"Mghxhu65tlUg"},"id":"Mghxhu65tlUg"},{"cell_type":"markdown","source":["# LSTM with pre-trained Glove Embedding"],"metadata":{"id":"jcYZDh3yVPJ9"},"id":"jcYZDh3yVPJ9"},{"cell_type":"code","source":["from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences"],"metadata":{"id":"AKfRizvbZiuQ"},"id":"AKfRizvbZiuQ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = Tokenizer(nb_words=15000)\n","tokenizer.fit_on_texts(headlines)\n","sequences = tokenizer.texts_to_sequences(headlines)\n","\n","word_index = tokenizer.word_index"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ftGvlefZe0I","executionInfo":{"status":"ok","timestamp":1704454473179,"user_tz":-60,"elapsed":341,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"d4097b32-d615-4e98-810b-3d3dbbc57857"},"id":"-ftGvlefZe0I","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/text.py:246: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["def load_glove_model(File):\n","    print(\"Loading Glove Model\")\n","    glove_model = {}\n","    with open(File,'r') as f:\n","        for line in f:\n","            split_line = line.split()\n","            word = split_line[0]\n","            embedding = np.array(split_line[1:], dtype=np.float64)\n","            glove_model[word] = embedding\n","    print(f\"{len(glove_model)} words loaded!\")\n","    return glove_model"],"metadata":{"id":"xozQcHDxXq4b"},"id":"xozQcHDxXq4b","execution_count":null,"outputs":[]},{"cell_type":"code","source":["glove_model = load_glove_model('glove.6B.100d.txt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B_R1HoIFXsjO","executionInfo":{"status":"ok","timestamp":1704453954815,"user_tz":-60,"elapsed":16481,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"f90fa30e-cf3e-4815-c06a-cfe69e8bb2a6"},"id":"B_R1HoIFXsjO","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading Glove Model\n","400000 words loaded!\n"]}]},{"cell_type":"code","source":["embedding_matrix = np.zeros((len(word_index) + 1, 100))\n","for word, i in word_index.items():\n","    embedding_vector = glove_model.get(word)\n","    if embedding_vector is not None:\n","        # words not found in embedding index will be all-zeros.\n","        embedding_matrix[i] = embedding_vector"],"metadata":{"id":"0yRRKX0JVOTV"},"id":"0yRRKX0JVOTV","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.layers import Embedding\n","\n","embedding_layer = Embedding(len(word_index) + 1,\n","                            100,\n","                            weights=[embedding_matrix],\n","                            input_length=x_train.shape[1],\n","                            trainable=False)"],"metadata":{"id":"oAO8b0o0Z_8A"},"id":"oAO8b0o0Z_8A","execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = tf.keras.models.Sequential()\n","model.add(embedding_layer)\n","model.add(tf.keras.layers.LSTM(100, return_sequences=True))\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(3, activation='softmax'))\n","\n","model.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer='adam',\n","    metrics=['accuracy']\n",")"],"metadata":{"id":"PaEJozLXaO74"},"id":"PaEJozLXaO74","execution_count":null,"outputs":[]},{"cell_type":"code","source":["start_time = time.time()\n","\n","history = model.fit(\n","    x_train,\n","    y_train,\n","    validation_split=0.2,\n","    batch_size=32,\n","    epochs=10,\n",")\n","\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print(\"Elapsed time: \", elapsed_time)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rrOFSmRUarCx","executionInfo":{"status":"ok","timestamp":1704454720426,"user_tz":-60,"elapsed":13224,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"df7b6538-2310-4505-a73d-102be55be2da"},"id":"rrOFSmRUarCx","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","85/85 [==============================] - 5s 17ms/step - loss: 0.8146 - accuracy: 0.6421 - val_loss: 0.7993 - val_accuracy: 0.6377\n","Epoch 2/10\n","85/85 [==============================] - 1s 9ms/step - loss: 0.6418 - accuracy: 0.7206 - val_loss: 0.7082 - val_accuracy: 0.6878\n","Epoch 3/10\n","85/85 [==============================] - 1s 8ms/step - loss: 0.5430 - accuracy: 0.7670 - val_loss: 0.7031 - val_accuracy: 0.7143\n","Epoch 4/10\n","85/85 [==============================] - 1s 7ms/step - loss: 0.5018 - accuracy: 0.7976 - val_loss: 0.7004 - val_accuracy: 0.7054\n","Epoch 5/10\n","85/85 [==============================] - 1s 7ms/step - loss: 0.4347 - accuracy: 0.8223 - val_loss: 0.6788 - val_accuracy: 0.7187\n","Epoch 6/10\n","85/85 [==============================] - 1s 7ms/step - loss: 0.3694 - accuracy: 0.8607 - val_loss: 0.7701 - val_accuracy: 0.7187\n","Epoch 7/10\n","85/85 [==============================] - 1s 8ms/step - loss: 0.3154 - accuracy: 0.8854 - val_loss: 0.7325 - val_accuracy: 0.7216\n","Epoch 8/10\n","85/85 [==============================] - 1s 6ms/step - loss: 0.2416 - accuracy: 0.9093 - val_loss: 0.8526 - val_accuracy: 0.6951\n","Epoch 9/10\n","85/85 [==============================] - 1s 7ms/step - loss: 0.2106 - accuracy: 0.9222 - val_loss: 0.8581 - val_accuracy: 0.7246\n","Epoch 10/10\n","85/85 [==============================] - 1s 7ms/step - loss: 0.1658 - accuracy: 0.9454 - val_loss: 0.9609 - val_accuracy: 0.7099\n","Elapsed time:  12.843188047409058\n"]}]},{"cell_type":"code","source":["_, acc = model.evaluate(x_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D6KOrWLjay5Y","executionInfo":{"status":"ok","timestamp":1704454738257,"user_tz":-60,"elapsed":880,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"29d82683-ac49-4cc3-c0c8-091b1eb1fa75"},"id":"D6KOrWLjay5Y","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["46/46 [==============================] - 1s 11ms/step - loss: 0.8523 - accuracy: 0.7352\n"]}]},{"cell_type":"code","source":["acc - 0.001*elapsed_time"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F6frrHqLa0mD","executionInfo":{"status":"ok","timestamp":1704454738258,"user_tz":-60,"elapsed":3,"user":{"displayName":"Jakov Vodanović","userId":"11106226652047902079"}},"outputId":"3d124167-0c43-4a90-eedf-4e519063d513"},"id":"F6frrHqLa0mD","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7223700320720673"]},"metadata":{},"execution_count":70}]},{"cell_type":"markdown","source":["Training with a pre-trained Embedding was significantly faster because most of the weights in these networks were tied to the Embedding. However, the results are relatively similar."],"metadata":{"id":"mcscy2yPt4V0"},"id":"mcscy2yPt4V0"},{"cell_type":"markdown","source":["# Conclusion"],"metadata":{"id":"1bHzVQVgeyy_"},"id":"1bHzVQVgeyy_"},{"cell_type":"markdown","source":["In all models, the accuracy on the training set reached up to 95 percent, while the validation and test set accuracy were significantly lower. I conclude that increasing the number of epochs wouldn't improve the model's performance; it might even harm it, indicating mild overfitting.\n","\n","<br>\n","\n","The best model was GRU without early stopping, achieving an accuracy of 74.07 percent on the test set. How satisfied can we be with this accuracy? Well, it's definitely better than the initial attempts with a simple RNN, but as we can see, none of the various models (which are more complex than GRU) achieved higher accuracy, mostly hovering around 73-74 percent. The conclusion of this project is that the dataset is simply too small. Part of the problem is also likely caused by the imbalance between positive, negative, and neutral news, with neutrals accounting for as much as 59 percent."],"metadata":{"id":"qlmQRWiLtrjS"},"id":"qlmQRWiLtrjS"}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"},"colab":{"provenance":[],"collapsed_sections":["continuous-target","WB2hD_dzsm-Z","RvRWkN5_cpRg","FzOE5sxItI_n","QHRfDOMbDjfA","67HF7BMQE94H","V9VQF6NEKSee","Tt5sK4kfPqyK","iNgHLShZQEv8","jcYZDh3yVPJ9","1bHzVQVgeyy_"],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}